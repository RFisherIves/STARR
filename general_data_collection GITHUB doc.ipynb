{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STARR Project - General Data Collection Routine\n",
    "Author: George Gorospe\n",
    "\n",
    "Note: This notebook draws heavily from Nvidia's jetbot code base found at: https://github.com/NVIDIA-AI-IOT/jetbot\n",
    "\n",
    "Before we can get started we need to ensure that we have the jetbot module installed. The jetbot module provides some useful tools that will help us collect data.\n",
    "\n",
    "If you encounter an error early in the is notebook it is likely that you'll need to downdload and install the jetbot module. To do this follow the next two steps:\n",
    "1. From a terminal on the nano, use: git clone https://github.com/NVIDIA-AI-IOT/jetbot.git\n",
    "2. Once inside your new jetbot folder, use: sudo python3 setup.py install\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "We can use this basic routine for collecting and labeling different types of data.\n",
    "Start by entering the name of the object you're photographing. The routine will create a new folder in your data sets directory for the data you collect.\n",
    "\n",
    "You'll want to take multiple photos of the object all by itself in differient orientations, locations, and lighting conditions. a good combination of all of these will ensure a robust AI capable of identifying the object with high accuracy.\n",
    "\n",
    "If you are collecting location data, i.e. gym, library, classroom, make sure to take photos of all the objects that will always be in the room. This means taking photos of the walls, desks, tables, trashcans, but not backpacks, coats, or note books.\n",
    "\n",
    "Final Note: This is experimental software, it has been tested in limited environments and may not do everything we expect. Use it, experiment with it, and feel free to change it. If you break the software you can always download it again from the source and experiment more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display live camera feed\n",
    "\n",
    "To start, we'll initialize and display the feed from our camera.\n",
    "Important part here is that we size the image to fit what our neural network.\n",
    "For certain tasks it may be better to collect larger images then downscale later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First we'll import some tools to help us get the camera started and to make this note book interactive\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import Image, display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to label the data we'll be collecting:\n",
    "use the text box to create a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # This library allows us to explore and modify the file structure on the Nano\n",
    "# Creating a function to add a folder to our directory\n",
    "def folder_function(label):\n",
    "    # Using the \"try/except\" statement here because the makedirs function can throw an error if the directory exists already\n",
    "    try:\n",
    "        os.makedirs('data/'+label)\n",
    "    except:\n",
    "        print('Directory no created because it already exists')\n",
    "    print(\"Creating data folder: data/\"+label)            \n",
    "    \n",
    "# Creating the interactive text box widget\n",
    "# Creating the interactive text box widget\n",
    "interactiveTextBox = interactive(folder_function,{'manual': True}, label = widgets.Text(value='structured_string',placeholder = 'structured_string',description='Enter Label:'));\n",
    "interactiveTextBox # calling the interactive element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you refresh the Jupyter file browser on the left, you should now see a new directory with your label.  \n",
    "\n",
    "Now we have a folder with our label, we're nearly ready to start saving images inside our folder.\n",
    "It is important to understand that the name of the image file is not important for our training purposes, only the folder name is important.\n",
    "This means that the images can have names like img1.jpg, tm223.jpg, cat.jpg, ect. But if they are all in a folder titled, \"dog\" then they will be interpreted as dogs.\n",
    "\n",
    "Since we don't want to manually name each image we collect, we'll use the ``uuid`` package in python, which defines the ``uuid1`` method to generate\n",
    "a unique identifier.  This unique identifier is generated from information like the current time and the machine address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "\n",
    "# the save snapshot function will collect an image and save it to file\n",
    "# This is a callback function, it is executed when we press a button to collect images\n",
    "def save_snapshot(directory):\n",
    "    global image_count\n",
    "    image_path = os.path.join(directory, str(uuid1()) + '.jpg')\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image.value)\n",
    "        image_count.value = len(os.listdir(directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the interative textbox for the number of photos and the button to collect images\n",
    "\n",
    "label = interactiveTextBox.children[0].value # take the label text from the interactive text box module\n",
    "directory = 'data/' + label\n",
    "button_layout = widgets.Layout(width='128px', height='64px')\n",
    "collect_button = widgets.Button(description='Collect Image', button_style='success', layout=button_layout)\n",
    "image_count = widgets.IntText(layout=button_layout, value=len(os.listdir(directory)))\n",
    "    \n",
    "# attach the callbacks, we use a 'lambda' function to ignore the\n",
    "# parameter that the on_click event would provide to our function\n",
    "# because we don't need it.\n",
    "collect_button.on_click(lambda x: save_snapshot(directory))\n",
    "display(image)\n",
    "display(widgets.HBox([image_count, collect_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we have an interface for collecting data we can go out and start collecting high quality images.\n",
    "\n",
    "Collect images of things that are the same class. Cups, shoes, books, backpacks.\n",
    "Vary the position and orientation of the object, the lighting, the ground surface.\n",
    "Try to have limited other things in the background, walls are fine, but you don't want to have other class objects.\n",
    "This means no banana for scale. Just the object we're interested in.\n",
    "\n",
    "Here are some tips for labeling data\n",
    "\n",
    "1. Try different orientations\n",
    "2. Try different lighting\n",
    "3. Try varied object / collision types; walls, ledges, objects\n",
    "4. Try different textured floors / objects;  patterned, smooth, glass, etc.\n",
    "\n",
    "Ultimately, the more data we have of scenarios the robot will encounter in the real world, the better our object classification and navigation (collision avoidance) performance  will be.  It's important\n",
    "to get *varied* data (as described by the above tips) and not just a lot of data, but you'll probably need at least 100 images of each class (that's not a science, just a helpful tip here).  But don't worry, it goes pretty fast once you get going :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "Once you've collected lots of images of each class, go back up to the top of the notebook and start again with a new class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
